{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"aba32b65"},"source":["### 1. Importing all the libraries\n","### Model used - Random Forest Regressor"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import statsmodels.api as sm\n","\n","import xgboost as xgb\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, TimeSeriesSplit\n","\n","import plotly.express as px\n","import plotly.io as pio\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import plotly.figure_factory as ff\n","from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n","init_notebook_mode(connected=False)\n","pio.renderers.default = 'colab'\n","pio.templates.default = 'ggplot2'\n","\n","from plotly.subplots import make_subplots"],"metadata":{"id":"InHtjlJ1cp5F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a6e834bc"},"source":["### 2. Read the CSV"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"65ce5bf1"},"outputs":[],"source":["df_train = pd.read_csv('train_preprocessed')\n","df_train.isna().any()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hruxbuz0CIxz"},"outputs":[],"source":["df_test = pd.read_csv('test_preprocessed')\n","df_test.isna().any()"]},{"cell_type":"markdown","metadata":{"id":"VKrEniWdCIxz"},"source":["### 3. Model Running"]},{"cell_type":"code","source":["# Convert 'date' column to datetime format\n","df_train['date'] = pd.to_datetime(df_train['date'])\n","df_test['date'] = pd.to_datetime(df_test['date'])\n","\n","# set 'sales' as target variable\n","y_train = df_train['sales']\n","X_train = df_train.drop('sales', axis=1)\n","\n","y_test = df_test['sales']\n","X_test = df_test.drop('sales', axis=1)"],"metadata":{"id":"EWBY9t3ED-lm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Select the columns\n","X_train = df_train[['special_offer', 'day of week', 'store_nbr','encoded_product_type','sales_lag365','sales_lag21','rolling_means7']].dropna()\n","y_train = df_train.loc[X_train.index, 'sales']\n","X_test = df_test[['special_offer', 'day of week', 'store_nbr','encoded_product_type','sales_lag365','sales_lag21','rolling_means7']].dropna()\n","y_test = df_test.loc[X_test.index, 'sales']\n","\n","# Initialize the model\n","model = xgb.XGBRegressor(n_estimators=1000, objective='reg:squarederror')\n","\n","# Fit the model\n","model.fit(X_train, y_train, verbose = False)\n","\n","# Make predictions\n","train_preds = model.predict(X_train)\n","test_preds = model.predict(X_test)\n","\n","# Calculate MAE\n","train_mae = mean_absolute_error(y_train, train_preds)\n","test_mae = mean_absolute_error(y_test, test_preds)\n","\n","# Calculate RMSE\n","train_rmse = mean_squared_error(y_train, train_preds, squared=False)\n","test_rmse = mean_squared_error(y_test, test_preds, squared=False)\n","\n","# Calculate R2 scores\n","train_r2 = r2_score(y_train, train_preds)\n","test_r2 = r2_score(y_test, test_preds)\n","\n","# Calculate Adjusted R2 scores\n","n_train = len(y_train)\n","p_train = X_train.shape[1]\n","train_adj_r2 = 1 - (1 - train_r2) * (n_train - 1) / (n_train - p_train - 1)\n","\n","n_test = len(y_test)\n","p_test = X_test.shape[1]\n","test_adj_r2 = 1 - (1 - test_r2) * (n_test - 1) / (n_test - p_test - 1)\n","\n","print(f'MAE on train set: {train_mae}')\n","print(f'MAE on test set: {test_mae}\\n')\n","print(f'RMSE on train set: {train_rmse}')\n","print(f'RMSE on test set: {test_rmse}\\n')\n","print(f'Adjusted R2 on train set: {train_adj_r2}')\n","print(f'Adjusted R2 on test set: {test_adj_r2}\\n')"],"metadata":{"id":"9-GR0B0QhtEl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#feature importance, then sorted by the importance value\n","\n","df_imp = pd.DataFrame(dict(Feature=X_train.columns, Importance = model.feature_importances_))\n","df_imp.sort_values(by=\"Importance\", ascending=False)"],"metadata":{"id":"ulWZjJ-iOBbN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"92Z22fCQCIx0"},"source":["### 4. Making Prediction at Training dataset"]},{"cell_type":"markdown","metadata":{"id":"e2BEUgp4CIx0"},"source":["Code below running 2 operations:\n","\n","1. Makes prediction for training datasets on the ‘special_offer’, ‘store_nbr’, ‘product_type’, ‘sales_lag7’, and ‘rolling_means7’ as predictors to 'predicted_sales' as target\n","\n","2. Displays the date, predicted value of each product at each store: It prints out the ‘date’, ‘store_nbr’, ‘product_type’, ‘sales’, and ‘predicted_sales’ columns of the df_train dataframe. This gives us a view of the actual and predicted sales for each product at each store on each date."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AUd2oRltCIx0"},"outputs":[],"source":["df_train.fillna(0, inplace=True)\n","df_test.fillna(0, inplace=True)\n","\n","# Make predictions for the test set\n","test_preds = model.predict(df_train[['special_offer', 'day of week', 'store_nbr','encoded_product_type','sales_lag365','sales_lag21','rolling_means7']])\n","\n","# Add the predictions to the DataFrame\n","df_train['predicted_sales'] = test_preds\n","\n","# Display the date, predicted value of each product at each store\n","print(df_train[['date', 'store_nbr', 'encoded_product_type','sales', 'predicted_sales']])\n"]},{"cell_type":"markdown","metadata":{"id":"A0thrXN0CIx1"},"source":["### 5. Setting Predicted sales of Training dataset to Plots."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vJKmLdDJCIx1"},"outputs":[],"source":["train_result_agg = df_train.set_index('date').resample('D')[['sales', 'predicted_sales']].mean().reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y7wTMSFeCIx1"},"outputs":[],"source":["fig = px.line(train_result_agg, x='date', y='sales', title='Actual vs Prediction Sales on Train dataset')\n","fig.add_scatter(x=train_result_agg['date'], y=train_result_agg['predicted_sales'], mode='lines')\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-PIRBKv-CIx1"},"outputs":[],"source":["store_train = df_train.groupby(['store_nbr', 'date'])[['sales', 'predicted_sales']].mean().reset_index()\n","store_df = store_train\n","fig = make_subplots(rows=18, cols=3, subplot_titles=[f'Store {store}' for store in store_train.store_nbr.unique()])\n","n=1\n","for row in range (1,19):\n","  for col in range(1,4):\n","    df = store_df[store_df['store_nbr'] == n]\n","    n += 1\n","\n","    px_fig = px.line(df, x='date', y='sales')\n","    px_fig.add_scatter(x=df['date'], y=df['predicted_sales'], mode='lines')\n","\n","    for trace in px_fig['data']:\n","      fig.add_trace(trace, row=row, col=col)\n","\n","fig.update_layout(height=4000, width=2000, title_text = 'Sales Prediction by Stores on Train dataset')\n","\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"28e8CiQBCIx1"},"outputs":[],"source":["product_test = df_train.groupby(['encoded_product_type', 'product_type', 'date'])[['sales', 'predicted_sales']].mean().reset_index()\n","product_df = product_test\n","fig = make_subplots(rows=11, cols=3, subplot_titles=[f'{product}' for product in product_test.product_type.unique()])\n","n=0\n","for row in range (1,12):\n","  for col in range(1,4):\n","    df = product_df[product_df['encoded_product_type'] == n]\n","    n += 1\n","\n","    px_fig = px.line(df, x='date', y='sales')\n","    px_fig.add_scatter(x=df['date'], y=df['predicted_sales'], mode='lines')\n","\n","    for trace in px_fig['data']:\n","      fig.add_trace(trace, row=row, col=col)\n","\n","fig.update_layout(height=4000, width=2000, title_text = 'Sales Prediction by Product on Train dataset')\n","\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{"id":"5acddd5f"},"source":["### --------------------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"1_fiM_OqCIx1"},"source":["### 6. Making Prediction at Test dataset (31 July - 15 August)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8aFjqncrCIx1"},"outputs":[],"source":["# Fill NaN values with 0\n","df_train.fillna(0, inplace=True)\n","df_test.fillna(0, inplace=True)\n","\n","# Make predictions for the test set\n","test_preds = model.predict(df_test[['special_offer', 'day of week', 'store_nbr','encoded_product_type','sales_lag365','sales_lag21','rolling_means7']])\n","\n","# Add the predictions to the DataFrame\n","df_test['predicted_sales'] = test_preds\n","\n","# Display the date, predicted value of each product at each store\n","print(df_test[['date', 'store_nbr', 'encoded_product_type','sales', 'predicted_sales']])\n"]},{"cell_type":"code","source":["test_result_agg = df_test.set_index('date').resample('D')[['sales', 'predicted_sales']].mean().reset_index()"],"metadata":{"id":"udl08rRGFdN3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig2 = px.line(test_result_agg, x='date', y='sales', title='Actual vs Prediction Sales on Test dataset')\n","fig2.add_scatter(x=test_result_agg['date'], y=test_result_agg['predicted_sales'], mode='lines')\n","fig2.show()\n"],"metadata":{"id":"_6yxIGTdFeZ6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w2qLam4lCIx1"},"source":["### 7. Setting Predicted sales of Test dataset to Plots."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjM9MPCiCIx1"},"outputs":[],"source":["store_train = df_test.groupby(['store_nbr', 'date'])[['sales', 'predicted_sales']].mean().reset_index()\n","store_df = store_train\n","fig = make_subplots(rows=18, cols=3, subplot_titles=[f'Store {store}' for store in store_train.store_nbr.unique()])\n","n=1\n","for row in range (1,19):\n","  for col in range(1,4):\n","    df = store_df[store_df['store_nbr'] == n]\n","    n += 1\n","\n","    px_fig = px.line(df, x='date', y='sales')\n","    px_fig.add_scatter(x=df['date'], y=df['predicted_sales'], mode='lines')\n","\n","    for trace in px_fig['data']:\n","      fig.add_trace(trace, row=row, col=col)\n","\n","fig.update_layout(height=4000, width=2000, title_text = 'Sales Prediction by Stores on Test dataset')\n","\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gC0amBy5CIx1"},"outputs":[],"source":["product_test = df_test.groupby(['encoded_product_type', 'product_type', 'date'])[['sales', 'predicted_sales']].mean().reset_index()\n","product_df = product_test\n","fig = make_subplots(rows=11, cols=3, subplot_titles=[f'{product}' for product in product_test.product_type.unique()])\n","n=0\n","for row in range (1,12):\n","  for col in range(1,4):\n","    df = product_df[product_df['encoded_product_type'] == n]\n","    n += 1\n","\n","    px_fig = px.line(df, x='date', y='sales')\n","    px_fig.add_scatter(x=df['date'], y=df['predicted_sales'], mode='lines')\n","\n","    for trace in px_fig['data']:\n","      fig.add_trace(trace, row=row, col=col)\n","\n","fig.update_layout(height=4000, width=2000, title_text = 'Sales Prediction by Product on Test dataset')\n","\n","fig.show()\n"]}]}